b1 = omega_to_b(omega1, kappa)
# Model 2
a2 = omega_to_a(omega2, kappa)
b2 = omega_to_b(omega2, kappa)
plot(dbeta(seq(0, 1, by = 0.01), 8, 12))
# Odds
prior1 = 0.5
prior2 = 0.5
# Calculate the evidences
evidence1 = beta_bernoulli_evidence(a1, b1, z, N)
evidence2 = beta_bernoulli_evidence(a2, b2, z, N)
# Calculate Bayes factor
bayes_factor = evidence1/evidence2
# Calculate odds
prior_odds = prior1/prior2
posterior_odds = bayes_factor * prior_odds
# Calculate posterior model probabilities:
model_probability1 = bayes_factor / (1 + posterior_odds)
model_probability2 = 1 - model_probability1
# Print results
cat('The posterior model probabilities are:')
cat('Model 1: ', model_probability1, '%')
cat('Model 2: ', model_probability2, '%')
source('~/.active-rstudio-document', echo=TRUE)
# Functions for calculating a and b
omega_to_a <- function(omega, kappa) {
a = omega * (kappa - 2) + 1
return(a)
}
omega_to_b <- function(omega, kappa) {
b = (1 - omega) * (kappa - 2) + 1
return(b)
}
# Function for calculating the model evidence
beta_bernoulli_evidence <- function(a, b, z, N) {
evidence = beta(z + a, N - z + b) / beta(a, b)
return(evidence)
}
# Observations: 8 heads out of 12 flips
z = 8
N = 12
omega1 = 0.25
omega2 = 0.75
kappa = 8
theta = seq(0, 1, by = 0.01)
# Model 1
a1 = omega_to_a(omega1, kappa)
b1 = omega_to_b(omega1, kappa)
# Model 2
a2 = omega_to_a(omega2, kappa)
b2 = omega_to_b(omega2, kappa)
plot(dbeta(seq(0, 1, by = 0.01), 8, 12))
# Odds
prior1 = 0.5
prior2 = 0.5
# Calculate the evidences
evidence1 = beta_bernoulli_evidence(a1, b1, z, N)
evidence2 = beta_bernoulli_evidence(a2, b2, z, N)
# Calculate Bayes factor
bayes_factor = evidence1/evidence2
# Calculate odds
prior_odds = prior1/prior2
posterior_odds = bayes_factor * prior_odds
# Calculate posterior model probabilities:
model_probability1 = bayes_factor / (1 + posterior_odds)
model_probability2 = 1 - model_probability1
# Print results
cat('The posterior model probabilities are:')
cat('Model 1: ', model_probability1, '%')
cat('Model 2: ', model_probability2, '%')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/AI Studie jaar 2/Bayesian Statistics/beta_example_model_comparison_analytic.R')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
b2 = omega_to_b(omega2, kappa)
# Functions for calculating a and b
omega_to_a <- function(omega, kappa) {
a = omega * (kappa - 2) + 1
return(a)
}
omega_to_b <- function(omega, kappa) {
b = (1 - omega) * (kappa - 2) + 1
return(b)
}
# Function for calculating the model evidence
beta_bernoulli_evidence <- function(a, b, z, N) {
evidence = beta(z + a, N - z + b) / beta(a, b)
return(evidence)
}
# Observations: 8 heads out of 12 flips
z = 8
N = 12
omega1 = 0.25
omega2 = 0.75
kappa = 170
theta = seq(0, 1, by = 0.01)
# Model 1
a1 = omega_to_a(omega1, kappa)
b1 = omega_to_b(omega1, kappa)
# Model 2
a2 = omega_to_a(omega2, kappa)
b2 = omega_to_b(omega2, kappa)
# Odds
prior1 = 0.5
prior2 = 0.5
# Calculate the evidences
evidence1 = beta_bernoulli_evidence(a1, b1, z, N)
evidence2 = beta_bernoulli_evidence(a2, b2, z, N)
# Calculate Bayes factor
bayes_factor = evidence1/evidence2
# Calculate odds
prior_odds = prior1/prior2
posterior_odds = bayes_factor * prior_odds
# Calculate posterior model probabilities:
model_probability1 = bayes_factor / (1 + posterior_odds)
model_probability2 = 1 - model_probability1
# Print results
cat('Bayes factor: ', signif(bayes_factor, 3), '\n')
cat('The posterior model probabilities are:\n')
cat('Model 1: ', signif(model_probability1, 2), '%\n')
cat('Model 2: ', signif(model_probability2, 2), '%')
source('~/.active-rstudio-document')
omega_to_a(0.25, 170)
omega_to_b(0.25, 170)
omega_to_a(0.75, 170)
omega_to_b(0.75, 170)
# Optional generic preliminaries:
graphics.off() # This closes all of R's graphics windows.
rm(list=ls())
# Required packages for this exercise.
require(rjags)
require(coda)
#source("DBDA2E-utilities.R")
## The distributions that we use here are available in R, but for clarity are made explicit here.
# Bernoulli(z,N | theta)
bernoulli_pdf <- function(theta, z, N) {
# Computes p(z,N|theta) = Bernoulli(theta|z,N)
pdf = theta^z * (1 - theta)^(N - z)
return(pdf)
}
# beta(theta | a, b)
beta_pdf <- function(theta, a, b) {
# Computes p(theta|a,b) = beta(theta|a,b)
pdf = theta^(a - 1) * (1 - theta)^(b - 1) / beta(a,b)
return(pdf)
}
# B(a+z, N-z+b) / B(a,b)
beta_bernoulli_evidence <- function(a, b, N, z) {
return( beta( z+a, N-z+b ) / beta( a, b ) ) # not numerically stable
}
# Define a range of theta's to compute the probability density for:
theta = seq(0, 1, by = 0.01)
# Observations: 6 heads out of 9 flips
z = 8
N = 12
# Hyperparameters
# Model 1
a1 = 43
b1 = 127
# Model 2
a2 = 127
b2 = 43
likelihood                  = bernoulli_pdf(theta, z = z, N = N)
prior1                      = beta_pdf(theta, a = a1, b = b1)
prior2                      = beta_pdf(theta, a = a2, b = b2)
posterior1                  = beta_pdf(theta, a = z + a1, b = N - z + b1) # Easy posterior, because conjugacy
posterior2                  = beta_pdf(theta, a = z + a2, b = N - z + b2) # Easy posterior, because conjugacy
# Plot the probability density functions
par(mfrow=c(2,3))
plot(theta, prior1, type='l')
title('Prior 1 (a=2.5, b=5.5)')
plot(theta, likelihood, type='l')
title('Likelihood (z=8, N=12)')
plot(theta, posterior1, type='l')
title('Posterior 1 (a=2.5+z, b=5.5+N-z)')
plot(theta, prior2, type='l')
title('Prior 2 (a=5.5, b=2.5)')
plot(theta, likelihood, type='l')
title('Likelihood (z=8, N=4)')
plot(theta, posterior2, type='l')
title('Posterior 2 (a=5.5+z, b=2.5+N-z)')
## NOW WE DO MODEL COMPARISON
evidence1 = beta_bernoulli_evidence(a1, b1, N, z)
show(sprintf('Evidence p(D|m_1) = %0.5f', evidence1))
evidence2 = beta_bernoulli_evidence(a2, b2, N, z)
show(sprintf('Evidence p(D|m_2) = %0.5f', evidence2))
bayes_factor = evidence1 / evidence2
show(sprintf('Bayes factor = %0.5f', bayes_factor))
show(sprintf('>1 : in favor of m1, <1 : in favor of m2'))
# I have no model preference
prior_model_1 = 0.5
prior_model_2 = 0.5
prior_odds = prior_model_1 / prior_model_2 # trivially 1.0 here
posterior_odds = bayes_factor * prior_odds # multiply with 1.0 is not very exciting
posterior_model1 = posterior_odds / (1.0 + posterior_odds)
posterior_model2 = 1 - posterior_model1
show(sprintf('Posterior model 1 p(m_1 | D) = %0.2f', posterior_model1))
show(sprintf('Posterior model 2 p(m_2 | D) = %0.2f', posterior_model2))
source('~/.active-rstudio-document')
# Emma Vriezen (s1010487) and Floris Griep (s1010793)
# Optional generic preliminaries:
graphics.off() # This closes all of R's graphics windows.
rm(list=ls())  # Careful! This clears all of R's memory!
# Required packages for this exercise.
require(rjags)
require(coda)
source("DBDA2Eprograms/DBDA2E-utilities.R")
sW = 277
nW = 412
sE = 2545
nE = 4241
winter_model = "
model {
## Prior
thetaE.prior ~ dbeta(1,1)
thetaW.prior ~ dbeta(1,1)
delta.prior <- abs(thetaE.prior-thetaW.prior)
thetaE ~ dbeta(1,1)
thetaW ~ dbeta(1,1)
delta <- abs(thetaE-thetaW)
## Likelihood
sE ~ dbinom(thetaE,nE)
sW ~ dbinom(thetaW,nW)
}
"
niter=10000
nchains=4
nsamples = niter*nchains
data <- list('sE' = sE, 'sW' = sW, 'nE' = nE, 'nW' = nW) # to be passed on to JAGS
parameters <- c('delta', 'delta.prior') # fill in!
jagsmodel_winter <- jags.model(textConnection(winter_model),
data = data,
n.chains = nchains)
samples_winter = coda.samples(jagsmodel_winter, parameters, n.iter = niter)
samples = as.matrix(samples_winter)
samples.post = samples[,'delta']
samples.prior =  samples[,'delta.prior']
nbreaks = 30
histogram1 <- hist(samples.post, breaks=nbreaks, plot=F)
histogram2 <- hist(samples.prior, breaks=nbreaks, plot=F)
binwidth1 = histogram1$breaks[2] - histogram1$breaks[1] # ***
binwidth2 = histogram2$breaks[2] - histogram2$breaks[1]
histogram1$counts = (histogram1$counts / nsamples) / binwidth1 # ***
histogram2$counts = (histogram2$counts / nsamples) / binwidth2
plot( histogram1, col=rgb(0,0,1,1/2), xlim=c(-1,1), xlab = expression(delta), ylab = 'Probability density')
plot( histogram2, col=rgb(1,0,0,1/2), xlim=c(-1,1), add=T)
# Comment out the next line once you've installed this package
library(polspline)
fit.posterior <- logspline(samples.post, lbound = -1, ubound = 1)
fit.prior <- logspline(samples.prior, lbound = -1, ubound = 1)
plot(fit.posterior, xlim = c(-1,1), add=T)
plot(fit.prior, xlim=c(-1,1), add=T)
title('Histograms and fitted curves')
nbreaks = 30
histogram1 <- hist(samples.post, breaks=nbreaks, plot=F)
histogram2 <- hist(samples.prior, breaks=nbreaks, plot=F)
binwidth1 = histogram1$breaks[2] - histogram1$breaks[1] # ***
binwidth2 = histogram2$breaks[2] - histogram2$breaks[1]
histogram1$counts = (histogram1$counts / nsamples) / binwidth1 # ***
histogram2$counts = (histogram2$counts / nsamples) / binwidth2
# Plot the histograms
plot( histogram1, col=rgb(0,0,1,1/2), xlim=c(-1,1), xlab = expression(delta), ylab = 'Probability density')
plot( histogram2, col=rgb(1,0,0,1/2), xlim=c(-1,1), add=T)
# Comment out the next line once you've installed this package
library(polspline)
fit.posterior <- logspline(samples.post, lbound = -1, ubound = 1)
fit.prior <- logspline(samples.prior, lbound = -1, ubound = 1)
plot(fit.posterior, xlim = c(-1,1), add=T)
plot(fit.prior, xlim=c(-1,1), add=T)
title('Histograms and fitted curves')
# Plot the histograms
plot( histogram1, col=rgb(0,0,1,1/2), xlim=c(-1,1), xlab = expression(delta), ylab = 'Probability density')
title('Histograms and fitted curves')
plot( histogram2, col=rgb(1,0,0,1/2), xlim=c(-1,1), add=T)
# Comment out the next line once you've installed this package
library(polspline)
fit.posterior <- logspline(samples.post, lbound = -1, ubound = 1)
fit.prior <- logspline(samples.prior, lbound = -1, ubound = 1)
plot(fit.posterior, xlim = c(-1,1), add=T)
plot(fit.prior, xlim=c(-1,1), add=T)
# Plot the histograms
plot( histogram1, col=rgb(0,0,1,1/2), xlim=c(-1,1), xlab = expression(delta), ylab = 'Probability density', title='Histograms and fitted curves')
# Plot the histograms
plot( histogram1, col=rgb(0,0,1,1/2), xlim=c(-1,1), xlab = expression(delta), ylab = 'Probability density', main='Histograms and fitted curves')
plot( histogram2, col=rgb(1,0,0,1/2), xlim=c(-1,1), add=T)
# Comment out the next line once you've installed this package
library(polspline)
fit.posterior <- logspline(samples.post, lbound = -1, ubound = 1)
fit.prior <- logspline(samples.prior, lbound = -1, ubound = 1)
plot(fit.posterior, xlim = c(-1,1), add=T)
plot(fit.prior, xlim=c(-1,1), add=T)
posterior_at_0 <- dlogspline(0, fit.posterior)
prior_at_0     <- dlogspline(0, fit.prior)
par(mfrow=c(1,2))
# Normal plot
plot(fit.posterior, xlim=c(-1,1), xlab = expression(delta), ylab = 'Probability density')
plot(fit.prior, add = T, lty = 2)
points(x=0, y=posterior_at_0, pch=19)
points(x=0, y=prior_at_0, pch=19)
title('Full distributions')
legend(x = 'topleft', 1.9, c('Posterior', 'Prior'), lty=c(1,2))
# Zoomed plot
plot(fit.posterior, xlab = expression(delta), ylab = 'Probability density', xlim = c(-0.1,0.1), ylim = c(-0.1,1)) # Set both xlim and ylim to zoom in.
plot(fit.prior, add = T, lty = 2, xlim = c(-0.1,0.1)) # You need to set the same xlim here for the plot to display properly.
# Add plotting of the circles at (delta, p(delta=0)). Hint: look up 'pch' for plotting in R
points(x=0, y=posterior_at_0, pch=19)
points(x=0, y=prior_at_0, pch=19)
title('Zoomed plot')
legend(x = 'topleft', 1.9, c('Posterior', 'Prior'), lty=c(1,2))
require(Rlab)
# 9 changing just one value more to heads will change the p value into being under 0.05 and allowing
# you to reject the null hypothesis
N = 250
probabilityDistribution =  rep(0, N)
for (n in 1:N){
probabilityDistribution[n] = dbinom(n,size = N, prob = 0.5)
}
pvalue = 0
for (n in 1:109){
pvalue = probabilityDistribution[n] + pvalue
}
for (n in 141:N){
pvalue = probabilityDistribution[n] + pvalue
}
pvalue
# 1
probabilityDistribution =  rep(0, N)
for (n in 1:N){
probabilityDistribution[n] = dbinom(n,size = N, prob = 0.5)
}
pvalue = 0
for (n in 1:110){
pvalue = probabilityDistribution[n] + pvalue
}
for (n in 140:N){
pvalue = probabilityDistribution[n] + pvalue
}
pvalue
theta1 = rbeta(1,1,1)
# 3,4
a = 600
alpha = 1:a
theta2 = 0.5
evidences = matrix (nrow = a, ncol =2)
Bayesfactor= rep(0,a)
nsamples = 100
for (o in alpha ){
evidence = 0
pvalue = 0
for (n in 1:nsamples){
theta1 = rbeta(1,o,o)
for (n in 1:N){
probabilityDistribution[n] = dbinom(n,size = N, prob = theta1)
}
for (n in 1:110){
pvalue = probabilityDistribution[n] + pvalue
}
for (n in 140:N){
pvalue = probabilityDistribution[n] + pvalue
}
evidence = evidence + pvalue
}
evidences[o,1] = (1/nsamples)*evidence
evidence2 = 0
pvalue2 = 0
for (n in 1:nsamples){ # This loop is dumb
for (n in 1:N){
probabilityDistribution[n] = dbinom(n,size = N, prob = theta2)
}
for (n in 1:110){
pvalue2 = probabilityDistribution[n] + pvalue2
}
for (n in 140:N){
pvalue2 = probabilityDistribution[n] + pvalue2
}
evidence2 = evidence2 + pvalue2
}
evidences[o,2] = (1/nsamples)*evidence2
Bayesfactor[o] = (evidences[o,1]/evidences[o,2])
}
Bayesfactor
plot(Bayesfactor)
abline(h=1)
min(Bayesfactor)
max(Bayesfactor)
#Bleep Bloop
require(Rlab)
# 9 changing just one value more to heads will change the p value into being under 0.05 and allowing
# you to reject the null hypothesis
N = 250
probabilityDistribution =  rep(0, N)
for (n in 1:N){
probabilityDistribution[n] = dbinom(n,size = N, prob = 0.5)
}
pvalue = 0
for (n in 1:109){
pvalue = probabilityDistribution[n] + pvalue
}
for (n in 141:N){
pvalue = probabilityDistribution[n] + pvalue
}
pvalue
# 1
probabilityDistribution =  rep(0, N)
for (n in 1:N){
probabilityDistribution[n] = dbinom(n,size = N, prob = 0.5)
}
pvalue = 0
for (n in 1:110){
pvalue = probabilityDistribution[n] + pvalue
}
for (n in 140:N){
pvalue = probabilityDistribution[n] + pvalue
}
pvalue
theta1 = rbeta(1,1,1)
# 3,4
a = 600
alpha = 1:a
theta2 = 0.5
evidences = matrix (nrow = a, ncol =2)
Bayesfactor= rep(0,a)
nsamples = 100
for (o in alpha ){
evidence = 0
pvalue = 0
for (n in 1:nsamples){
theta1 = rbeta(1,o,o)
for (n in 1:N){
probabilityDistribution[n] = dbinom(n,size = N, prob = theta1)
}
for (n in 1:110){
pvalue = probabilityDistribution[n] + pvalue
}
for (n in 140:N){
pvalue = probabilityDistribution[n] + pvalue
}
evidence = evidence + pvalue
}
evidences[o,1] = (1/nsamples)*evidence
evidence2 = 0
pvalue2 = 0
for (n in 1:nsamples){ # This loop is dumb
for (n in 1:N){
probabilityDistribution[n] = dbinom(n,size = N, prob = theta2)
}
for (n in 1:110){
pvalue2 = probabilityDistribution[n] + pvalue2
}
for (n in 140:N){
pvalue2 = probabilityDistribution[n] + pvalue2
}
evidence2 = evidence2 + pvalue2
}
evidences[o,2] = (1/nsamples)*evidence2
Bayesfactor[o] = (evidences[o,1]/evidences[o,2])
}
Bayesfactor
plot(Bayesfactor)
abline(h=1)
min(Bayesfactor)
files = list.files(pattern="*.csv")
library(data.table)
test = lapply(files, fread)
setwd("~/")
setwd("~/AI Master year 1/HRI/HRI-Dance-Project/Experiment/responses")
files = list.files(pattern="*.csv")
test = lapply(files, fread)
View(test)
View(test)
DT = do.call(rbind, lapply(files, fread))
files = list.files(pattern="*.csv")
DT = do.call(rbind, lapply(files, fread))
file_names <- dir() #where you have your files
your_data_frame <- do.call(rbind,lapply(file_names,read.csv))
file_names[-2];
file_names[-5];
file_names <- file_names[-5];
your_data_frame <- do.call(rbind,lapply(file_names,read.csv))
files = list.files(pattern="*.csv")
files <- files[-5]
DT = do.call(rbind, lapply(files, fread))
files <- files[-12]
DT = do.call(rbind, lapply(files, fread))
DT = do.call(rbind.fill, lapply(files, fread))
o
multmerge = function(mypath){
filenames=list.files(path=mypath, full.names=TRUE)
datalist = lapply(filenames, function(x){read.csv(file=x,header=T)})
Reduce(function(x,y) {merge(x,y)}, datalist)
}
multmerge("")
multmerge()
multmerge(dir())
multmerge("C:\Users\emmav\Documents\AI Master year 1\HRI\HRI-Dance-Project\Experiment\responses")
multmerge(r"C:\Users\emmav\Documents\AI Master year 1\HRI\HRI-Dance-Project\Experiment\responses")
multmerge("C:/Users/emmav/Documents/AI Master year 1/HRI/HRI-Dance-Project/Experiment/responses")
list <- multmerge("C:/Users/emmav/Documents/AI Master year 1/HRI/HRI-Dance-Project/Experiment/responses")
View(list)
temp = list.files(pattern="*.csv")
myfiles = do.call(rbind, lapply(temp, read.delim))
file_names <- dir() #where you have your files
your_data_frame <- do.call(rbind,lapply(file_names,read.csv))
files = list.files(pattern="*.csv")
DT = do.call(rbind, lapply(files, fread))
test = lapply(files, fread)
